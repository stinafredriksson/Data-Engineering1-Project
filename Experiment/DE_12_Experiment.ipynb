{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "66df7b76-1bf9-4816-945f-162c19e2e582",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/14 13:00:03 WARN StandaloneSchedulerBackend: Dynamic allocation enabled without spark.executor.cores explicitly set, you may get more executors allocated than expected. It's recommended to set spark.executor.cores explicitly. Please check SPARK-30299 for more details.\n",
      "[Stage 0:======================================================>(146 + 1) / 147]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- author: string (nullable = true)\n",
      " |-- body: string (nullable = true)\n",
      " |-- content: string (nullable = true)\n",
      " |-- content_len: long (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- normalizedBody: string (nullable = true)\n",
      " |-- subreddit: string (nullable = true)\n",
      " |-- subreddit_id: string (nullable = true)\n",
      " |-- summary: string (nullable = true)\n",
      " |-- summary_len: long (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      "\n",
      "Time to load the dataset (seconds): 80.50780272483826 seconds\n",
      "Time to load the dataset (minutes): 1.3417967120806376 minutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from pyspark.sql import SparkSession\n",
    "from operator import add\n",
    "from pyspark.sql.functions import explode, split, desc, col\n",
    "\n",
    "#################### Setup spark session ####################\n",
    "\n",
    "# Stop running SparkSession if it exists\n",
    "if 'spark_session' in locals():\n",
    "    spark_session.stop()\n",
    "    \n",
    "spark_session = SparkSession\\\n",
    "        .builder\\\n",
    "        .master(\"spark://192.168.2.224:7077\") \\\n",
    "        .appName(\"Experiment\")\\\n",
    "        .config(\"spark.dynamicAllocation.enabled\", True)\\\n",
    "        .config(\"spark.dynamicAllocation.shuffleTracking.enabled\",True)\\\n",
    "        .config(\"spark.shuffle.service.enabled\", False)\\\n",
    "        .config(\"spark.dynamicAllocation.executorIdleTimeout\",\"30s\")\\\n",
    "        .config(\"spark.driver.port\",9999)\\\n",
    "        .config(\"spark.blockManager.port\",10005)\\\n",
    "        .getOrCreate()\n",
    "\n",
    "# RDD API\n",
    "spark_context = spark_session.sparkContext\n",
    "\n",
    "# Start time\n",
    "start_time = time.time()\n",
    "\n",
    "# Load reddit data\n",
    "reddit_df = spark_session.read.json(\"hdfs://192.168.2.224:9000/user/ubuntu/reddit/corpus-webis-tldr-17.json\")\n",
    "\n",
    "reddit_df.printSchema()\n",
    "\n",
    "# End time\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate duration\n",
    "duration_sec = end_time - start_time\n",
    "duration_min = duration_sec / 60\n",
    "\n",
    "# Print duration\n",
    "print(\"Time to load the dataset (seconds):\", duration_sec, \"seconds\")\n",
    "print(\"Time to load the dataset (minutes):\", duration_min, \"minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "26d13a75-0088-4df8-bae1-f49f73687060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 of the most popular subreddits\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------+\n",
      "|          subreddit| count|\n",
      "+-------------------+------+\n",
      "|          AskReddit|589947|\n",
      "|      relationships|352049|\n",
      "|    leagueoflegends|109307|\n",
      "|               tifu| 52219|\n",
      "|relationship_advice| 50416|\n",
      "|              trees| 47286|\n",
      "|             gaming| 43851|\n",
      "|            atheism| 43268|\n",
      "|      AdviceAnimals| 40783|\n",
      "|              funny| 40171|\n",
      "+-------------------+------+\n",
      "only showing top 10 rows\n",
      "\n",
      "Top 10 of the most frequent occurring words:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+\n",
      "|word|   count|\n",
      "+----+--------+\n",
      "| the|38303658|\n",
      "|  to|34684398|\n",
      "|   I|34223440|\n",
      "| and|32121991|\n",
      "|   a|27233249|\n",
      "|  of|19675785|\n",
      "|that|13871944|\n",
      "|  in|13539182|\n",
      "|  is|11695201|\n",
      "|  my|11226285|\n",
      "+----+--------+\n",
      "only showing top 10 rows\n",
      "\n",
      "Top 10 authors with the most bad words:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 53:============================================>           (15 + 4) / 19]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------+\n",
      "|            author| count|\n",
      "+------------------+------+\n",
      "|         [deleted]|769514|\n",
      "|      iamtotalcrap|  5721|\n",
      "|        Furiousmoe|  1951|\n",
      "|           codayus|  1853|\n",
      "|           DejaBoo|  1365|\n",
      "|        pixis-4950|  1347|\n",
      "|       Death_Star_|  1205|\n",
      "|        Typhos1234|   977|\n",
      "|ExceptionToTheRule|   974|\n",
      "|           p_U_c_K|   948|\n",
      "+------------------+------+\n",
      "only showing top 10 rows\n",
      "\n",
      "Time to run the experiment (seconds): 196.07083868980408 seconds\n",
      "Time to run the experiment (minutes): 3.267847311496735 minutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Start time\n",
    "start_time = time.time()\n",
    "\n",
    "#################### Most popular subreddits ####################\n",
    "\n",
    "# Group by subreddit and count occurrences\n",
    "popular_subreddits = reddit_df.groupBy(\"subreddit\").count()\n",
    "\n",
    "# Sort by count in descending order to find the most popular subreddits\n",
    "popular_subreddits = popular_subreddits.orderBy(desc(\"count\"))\n",
    "\n",
    "# Show the top 10 most popular subreddits\n",
    "print(\"Top 10 of the most popular subreddits\\n\")\n",
    "popular_subreddits.show(10)\n",
    "\n",
    "#################### Most frequent occurring words ####################\n",
    "\n",
    "# Tokenize the text data in the body column\n",
    "words = reddit_df.select(explode(split(reddit_df.body, \"\\\\s+\")).alias(\"word\"))\n",
    "\n",
    "# Count occurrences of each word\n",
    "word_counts = words.groupBy(\"word\").count()\n",
    "\n",
    "# Sort by count in descending order to find the most frequent words\n",
    "most_frequent_words = word_counts.orderBy(desc(\"count\"))\n",
    "\n",
    "# Show the top 10 most frequent words\n",
    "print(\"Top 10 of the most frequent occurring words:\\n\")\n",
    "most_frequent_words.show(10)\n",
    "\n",
    "#################### Authors with the most bad words used ####################\n",
    "\n",
    "# Tokenize the text in the 'body' column to extract individual words\n",
    "words_df = reddit_df.select(\"id\", explode(split(reddit_df.body, \"\\\\s+\")).alias(\"word\"))\n",
    "\n",
    "# Load the list of bad words\n",
    "with open(\"full-list-of-bad-words_text-file_2022_05_05.txt\", \"r\") as file:\n",
    "    lines = [line.strip() for line in file.readlines()]\n",
    "    bad_words = lines\n",
    "\n",
    "# Filter words to select only bad words\n",
    "bad_words_df = words_df.filter(words_df.word.isin(bad_words))\n",
    "\n",
    "# Group by bad words and count occurrences\n",
    "bad_word_counts_df = bad_words_df.groupBy(\"word\").count()\n",
    "\n",
    "# Sort by count of bad words in descending order\n",
    "sorted_bad_word_counts_df = bad_word_counts_df.orderBy(col(\"count\").desc())\n",
    "\n",
    "# Show the top 10 most used bad words\n",
    "# sorted_bad_word_counts_df.show(10)\n",
    "\n",
    "# Group by author and count bad words\n",
    "bad_words_count_df = bad_words_df.join(reddit_df, \"id\").groupBy(\"author\").count()\n",
    "\n",
    "# Sort by count of bad words in descending order\n",
    "sorted_bad_words_count_df = bad_words_count_df.orderBy(col(\"count\").desc())\n",
    "\n",
    "# Show the top 10 authors with the most bad words\n",
    "print(\"Top 10 authors with the most bad words:\\n\")\n",
    "sorted_bad_words_count_df.show(10)\n",
    "\n",
    "#################### Execution time measurement ####################\n",
    "\n",
    "# End time\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate duration\n",
    "duration_sec = end_time - start_time\n",
    "duration_min = duration_sec / 60\n",
    "\n",
    "# Print duration\n",
    "print(\"Time to run the experiment (seconds):\", duration_sec, \"seconds\")\n",
    "print(\"Time to run the experiment (minutes):\", duration_min, \"minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9daee0-0e4c-40b6-b443-64566de1be6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### Stop spark session ####################\n",
    "\n",
    "# release the cores for another application/experiment!\n",
    "spark_context.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
